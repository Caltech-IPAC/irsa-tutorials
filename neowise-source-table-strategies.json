{"version":2,"kind":"Notebook","sha256":"363dbb29be11f006e7b9eaba561c12f75725dd8eab381a49459e786979023057","slug":"neowise-source-table-strategies","location":"/tutorials/parquet-catalog-demos/neowise-source-table-strategies.md","dependencies":[],"frontmatter":{"title":"Strategies to Efficiently Work with NEOWISE Single-exposure Source Table in Parquet","kernelspec":{"name":"python3","display_name":"science_demo","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.16.1"}},"skip_execution":true,"content_includes_title":false,"authors":[{"id":"IRSA Scientists and Developers","name":"IRSA Scientists and Developers"}],"github":"https://github.com/Caltech-IPAC/irsa-tutorials/","subject":"IRSA Tutorials","keywords":["astronomy"],"settings":{"output_matplotlib_strings":"remove"},"numbering":{"title":{"offset":2}},"edit_url":"https://github.com/Caltech-IPAC/irsa-tutorials//blob/main/tutorials/parquet-catalog-demos/neowise-source-table-strategies.md","exports":[{"format":"md","filename":"neowise-source-table-strategies.md","url":"/irsa-tutorials/build/neowise-source-table-981ab80a430746343c4193da312f424c.md"}]},"mdast":{"type":"root","children":[{"type":"block","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"An executed version of this notebook can be seen on\n","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"k5ts7xHdcG"},{"type":"link","url":"https://irsa.ipac.caltech.edu/docs/notebooks/neowise-source-table-strategies.html","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"IRSA’s website","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"ynYSjORYTw"}],"urlSource":"https://irsa.ipac.caltech.edu/docs/notebooks/neowise-source-table-strategies.html","key":"DA2DZvBWiK"},{"type":"text","value":".","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"P7q1z2bDid"}],"key":"KnEp8CQjgD"}],"key":"qMw17XqbIY"},{"type":"block","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"This notebook discusses strategies for working with the Apache Parquet version of the\n","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"FPb5YC1N2L"},{"type":"link","url":"https://irsa.ipac.caltech.edu/Missions/wise.html","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"NEOWISE","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"kVxqySI5Sp"}],"urlSource":"https://irsa.ipac.caltech.edu/Missions/wise.html","key":"WGJVAoDYRG"},{"type":"text","value":" Single-exposure Source Table\nand provides the basic code needed for each approach.\nThis is a very large catalog -- 11 years and 42 terabytes in total with 145 columns and 200 billion rows.\nMost of the work shown in this notebook is how to efficiently deal with so much data.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"rWRrbeku7v"}],"key":"e9wyoplr2l"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Learning Goals:","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"Wir4rToD7t"}],"key":"fw6Pz9S3G1"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":33,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Identify use cases that will benefit most from using this Parquet format.","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"a6qq9BLfS5"}],"key":"U50zAjWDA0"},{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Understand how this dataset is organized and three different ways to efficiently\nslice it in order to obtain a subset small enough to load into memory and process.","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"F3sVNuZa4u"}],"key":"VrRPW2Z4tY"},{"type":"listItem","spread":true,"position":{"start":{"line":36,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Feel prepared to apply these methods to a new use case and determine efficient filtering and slicing options.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"Zc83gMC9vv"}],"key":"KiAq0uyHRv"}],"key":"d1zZy0GhW5"}],"key":"r4h3mTeJ5d"},{"type":"block","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"1. Introduction","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"if2olguCNu"}],"identifier":"id-1-introduction","label":"1. Introduction","html_id":"id-1-introduction","implicit":true,"key":"kkUB2oIHVe"}],"key":"ODKITAfRPY"},{"type":"block","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":44,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"The NEOWISE Single-exposure Source Table comprises 11 years of data.\nEach year on its own would be considered “large” compared to astronomy catalogs produced\ncontemporaneously, so working with the full dataset requires extra consideration.\nIn this Parquet version, each year is stored as an independent Parquet dataset.\nThis tutorial shows how to combine them and work with all years as one.\nThe data are partitioned by HEALPix (","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"bpvl1KzaO3"},{"type":"cite","url":"https://doi.org/10.1086/427976","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Górski et al., 2005","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"OzB0T1iA03"}],"kind":"narrative","label":"Gorski_2005","identifier":"https://doi.org/10.1086/427976","enumerator":"1","key":"Y0PycFda44"},{"type":"text","value":") order k=5.\nHEALPix is a tessellation of the sky, so partitioning the dataset this way makes it especially\nefficient for spatial queries.\nIn addition, the access methods shown below are expected to perform well when parallelized.","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"Ypo1fMyvFh"}],"key":"pqfQPwRNqW"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"The terms “partition”, “filter”, and “slice” all relate to subsets of data.\nIn this notebook we’ll use them with definitions that overlap but are not identical, as follows.\nA “partition” includes all data observed in a single HEALPix pixel.\nThis data is grouped together in the Parquet files.\nA “filter” is a set of criteria defined by the user and applied when reading data so that only the desired rows are loaded.\nWe’ll use it exclusively to refer to a PyArrow ","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"Uuyj7C9gT5"},{"type":"inlineCode","value":"filter","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"R0w4m7p959"},{"type":"text","value":".\nThe criteria can include partitions and/or any other column in the dataset.\nA “slice” is a generic subset of data.\nThere are a few ways to obtain a slice; one is by applying a filter.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"wLiTBaGfqd"}],"key":"fTl5kssYsm"},{"type":"paragraph","position":{"start":{"line":64,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"This notebook is expected to require about 2 CPUs and 50G RAM and to complete in about 10 minutes.\nThese estimates are based on testing in science platform environments.\nYour numbers will vary based on many factors including compute power, bandwidth, and physical distance from the data.\nThe required RAM and runtime can be reduced by limiting the number of NEOWISE years loaded.","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"gWwEB3QNDb"}],"key":"qn7fe7jXcM"}],"key":"WVu5ZAlhAb"},{"type":"block","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"1.1 When to use the Parquet version","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"vKsm8xQBuS"}],"identifier":"id-1-1-when-to-use-the-parquet-version","label":"1.1 When to use the Parquet version","html_id":"id-1-1-when-to-use-the-parquet-version","implicit":true,"key":"F7KvfBmw1l"},{"type":"paragraph","position":{"start":{"line":73,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"IRSA provides large catalogs in file formats (e.g., Parquet) primarily to support use cases that require bulk access.\nThe Parquet version of the NEOWISE Source Table, coupled with the methods demonstrated in this tutorial,\nare expected to be the most efficient option for large-ish use cases like classifying, clustering, or\nbuilding light curves for many objects.\nIn general, the efficiency will increase with the number of rows required from each slice because the slice\nonly needs to be searched once regardless of the number of rows that are actually loaded.\nIn addition, this access route tends to perform well when parallelized.\nNote that these use cases (including this notebook) are often too large for a laptop and may perform\npoorly and/or crash if attempted.","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"PlJPSyBCX5"}],"key":"FBbyJyEBmf"},{"type":"paragraph","position":{"start":{"line":83,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"For small-ish use cases like searching for a handful of objects, other access routes like\nPyVO and TAP queries will be faster.","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"UEZAMqeBpv"}],"key":"udJVFmwfHU"},{"type":"paragraph","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"text","value":"Consider using this tutorial if either of the following is true:","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"Lmo04FUvE2"}],"key":"riN0F72XYK"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":88,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"Your use case is large enough that you are considering parallelizing your code to speed it up.","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"el7IPPjCJ5"}],"key":"jd33bttO7O"},{"type":"listItem","spread":true,"position":{"start":{"line":89,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"text","value":"Your sample size is large enough that loading the data using a different method is likely to\ntake hours, days, or longer.","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"ZIFEziIiKz"}],"key":"RA8GOd4wcK"}],"key":"goIXJMpQ7d"}],"key":"YhevMbRCH0"},{"type":"block","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"1.2 Recommended approach","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"KsG8Q1kmJK"}],"identifier":"id-1-2-recommended-approach","label":"1.2 Recommended approach","html_id":"id-1-2-recommended-approach","implicit":true,"key":"yKL0Z6lPRs"},{"type":"paragraph","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"children":[{"type":"text","value":"The basic process is:","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"bJlKXksJ29"}],"key":"eBIZzJ85fF"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":98,"column":1},"end":{"line":105,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"children":[{"type":"text","value":"Load the catalog metadata as a PyArrow dataset.","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"a5KEt2aurn"}],"key":"v8aiKWTdeD"},{"type":"listItem","spread":true,"position":{"start":{"line":99,"column":1},"end":{"line":99,"column":1}},"children":[{"type":"text","value":"Decide how to slice the dataset (e.g., by year, partition, and/or file) depending on your use case.","position":{"start":{"line":99,"column":1},"end":{"line":99,"column":1}},"key":"woGQD0aPio"}],"key":"c9dPC77pbn"},{"type":"listItem","spread":true,"position":{"start":{"line":100,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Iterate and/or parallelize over the slices. For each slice:","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"key":"T7LOFtJk37"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":101,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"children":[{"type":"text","value":"Use the PyArrow dataset to load data of interest, applying row filters during the read.","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"HNheLCS6Ku"}],"key":"Bt6qByTA3v"},{"type":"listItem","spread":true,"position":{"start":{"line":102,"column":1},"end":{"line":102,"column":1}},"children":[{"type":"text","value":"Process the data as you like (e.g., cluster, classify, etc.).","position":{"start":{"line":102,"column":1},"end":{"line":102,"column":1}},"key":"a4XgNFFwY8"}],"key":"uwrCOvM52Z"},{"type":"listItem","spread":true,"position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Write your results to disk and/or return them for further processing.","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"key":"bQjdwllJ78"}],"key":"DBjx7TK4O8"}],"key":"rXJst6pVAr"}],"key":"so3Loc1tNn"},{"type":"listItem","spread":true,"position":{"start":{"line":104,"column":1},"end":{"line":105,"column":1}},"children":[{"type":"text","value":"(Optional) Concatenate your results and continue processing.","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"key":"aGd1qWwULC"}],"key":"UXhNWpJm2c"}],"key":"zQxzyFGkI0"},{"type":"paragraph","position":{"start":{"line":106,"column":1},"end":{"line":108,"column":1}},"children":[{"type":"text","value":"This notebook covers steps 1 through 3.1 and indicates where to insert your own code to proceed with 3.2.\nHere we iterate over slices, but the same code can be parallelized using any multi-processing framework.\nA fully-worked example is shown in the light curve notebook linked below.","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"key":"KEzxoWW4oy"}],"key":"AvDjPF9f9u"}],"key":"frTFaOnKWo"},{"type":"block","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"1.3 See also","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"eustybRcLA"}],"identifier":"id-1-3-see-also","label":"1.3 See also","html_id":"id-1-3-see-also","implicit":true,"key":"kPvl25Dwjg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":114,"column":1},"end":{"line":117,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"children":[{"type":"link","url":"https://irsa.ipac.caltech.edu/docs/notebooks/cloud-access-intro.html","position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"children":[{"type":"text","value":"IRSA Cloud Access Intro","position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"key":"rYjFYMAyJY"}],"urlSource":"https://irsa.ipac.caltech.edu/docs/notebooks/cloud-access-intro.html","key":"d7XDfzKJQ7"}],"key":"VzjWVWO6jB"},{"type":"listItem","spread":true,"position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"link","url":"https://irsa.ipac.caltech.edu/docs/notebooks/wise-allwise-catalog-demo.html","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"AllWISE Source Catalog Demo","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"Iu2OQ0cHzy"}],"urlSource":"https://irsa.ipac.caltech.edu/docs/notebooks/wise-allwise-catalog-demo.html","key":"yrDRM7CDyj"}],"key":"maNCw43EMC"},{"type":"listItem","spread":true,"position":{"start":{"line":116,"column":1},"end":{"line":117,"column":1}},"children":[{"type":"link","url":"https://irsa.ipac.caltech.edu/docs/notebooks/neowise-source-table-lightcurves.html","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"children":[{"type":"text","value":"Make Light Curves from NEOWISE Single-exposure Source Table","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"a3xA05meuV"}],"urlSource":"https://irsa.ipac.caltech.edu/docs/notebooks/neowise-source-table-lightcurves.html","key":"TWg0gS3sr9"}],"key":"PpAEZr3oyg"}],"key":"i6FtpmTXDN"}],"key":"a7TPdFiMSf"},{"type":"block","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"children":[{"type":"text","value":"2. Imports","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"key":"wDkY0nm4I0"}],"identifier":"id-2-imports","label":"2. Imports","html_id":"id-2-imports","implicit":true,"key":"Udq9YlWytm"}],"key":"JDWyFkATcm"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Uncomment the next line to install dependencies if needed.\n# !pip install hpgeom pandas pyarrow","key":"JJelw76Fke"},{"type":"output","id":"OsP4F3kjJ95SRc0-fc7K7","data":[],"key":"bQ8Y9GHib8"}],"key":"pjQJNFpHuc"},{"type":"block","children":[],"key":"UHV1rpDxZe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import re  # parse strings\nimport sys  # check size of loaded data\n\nimport hpgeom  # HEALPix math\nimport pandas as pd  # store and manipulate table data\nimport pyarrow.compute  # construct dataset filters\nimport pyarrow.dataset  # load and query the NEOWISE dataset\nimport pyarrow.fs  # interact with the S3 bucket storing the NEOWISE catalog","key":"BVc0cJTkkp"},{"type":"output","id":"cniVW-8UjlKnfnzt_JGWm","data":[],"key":"BMr2ZySyEg"}],"key":"mghT7iPjb0"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"text","value":"3. Setup","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"CrDg6K15uI"}],"identifier":"id-3-setup","label":"3. Setup","html_id":"id-3-setup","implicit":true,"key":"HaDahAkkCF"},{"type":"heading","depth":3,"position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"children":[{"type":"text","value":"3.1 Define variables and helper functions","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"mlVrvF6JR4"}],"identifier":"id-3-1-define-variables-and-helper-functions","label":"3.1 Define variables and helper functions","html_id":"id-3-1-define-variables-and-helper-functions","implicit":true,"key":"Stonfh4i78"}],"key":"MEN3F1nRff"},{"type":"block","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":144,"column":1},"end":{"line":145,"column":1}},"children":[{"type":"text","value":"Choose which NEOWISE years to include.\nExpect the notebook to require about 4G RAM and 1 minute of runtime per year.","position":{"start":{"line":144,"column":1},"end":{"line":144,"column":1}},"key":"CNpEYzhFZa"}],"key":"GEmWCc7m4u"}],"key":"vgHzh97JgP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# All NEOWISE years => about 40G RAM and 10 minutes runtime\nYEARS = [f\"year{yr}\" for yr in range(1, 12)] + [\"addendum\"]\n\n# To reduce the needed RAM or runtime, uncomment the next line and choose your own years.\n# Years 1 and 8 are needed for the median_file and biggest_file (defined below).\n# YEARS = [1, 8]","key":"qiZNFQt1vK"},{"type":"output","id":"H5GN9KxHNsP11drWRcOca","data":[],"key":"EjaxiBemop"}],"key":"bOseYPb6sw"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"children":[{"type":"text","value":"Column and partition variables:","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"key":"WeRSe7vegh"}],"key":"L9BHfbWOOK"}],"key":"eCynMyY3vi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# subset of columns to load\nflux_columns = [\"w1flux\", \"w1sigflux\", \"w2flux\", \"w2sigflux\"]\nCOLUMN_SUBSET = [\"cntr\", \"source_id\", \"ra\", \"dec\"] + flux_columns\n\n# partitioning info. do not change these values.\nK = 5  # healpix order of the catalog partitioning\nKCOLUMN = \"healpix_k5\"  # partitioning column name\nKFIELD = pyarrow.compute.field(KCOLUMN)  # pyarrow compute field, to be used in filters","key":"s62GwHiOs3"},{"type":"output","id":"_-P4kEEfguL0i_6_sEGbq","data":[],"key":"lxiLUQZv4Q"}],"key":"zePgvmlDnn"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"children":[{"type":"text","value":"Paths:","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"KlgvYWT59h"}],"key":"EIIPrQeRAZ"}],"key":"FKNTNah6G4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# We're going to look at several different files, so make a function to return the path.\ndef neowise_path(year, file=\"_metadata\"):\n    \"\"\"Return the path to a file. Default is \"_metadata\" file of the given year's dataset.\n\n    Parameters\n    ----------\n    year : int\n        NEOWISE year for which the path is being generated.\n    file : str\n        The name of the file to the returned path.\n\n    Returns\n    -------\n    str\n        The path to the file.\n    \"\"\"\n    # This information can be found at https://irsa.ipac.caltech.edu/cloud_access/.\n    bucket = \"nasa-irsa-wise\"\n    base_prefix = \"wise/neowiser/catalogs/p1bs_psd/healpix_k5\"\n    root_dir = f\"{bucket}/{base_prefix}/{year}/neowiser-healpix_k5-{year}.parquet\"\n    return f\"{root_dir}/{file}\"","key":"it8ciocXAE"},{"type":"output","id":"lsuhEfqORPblk1sIe7tgU","data":[],"key":"gatKEcb4uX"}],"key":"g9U4P0wY5G"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":195,"column":1},"end":{"line":195,"column":1}},"children":[{"type":"text","value":"Some representative partitions and files (see dataset stats in the Appendix for how we determine these values):","position":{"start":{"line":195,"column":1},"end":{"line":195,"column":1}},"key":"Fq3yGsghNS"}],"key":"q03qW75JTL"}],"key":"K5WauCpv20"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# pixel index of the median partition and the biggest partition by number of rows\nmedian_part = 11_831\nbiggest_part = 8_277\n\n# path to the median file and the biggest file by file size on disk (see Appendix)\nmedian_file = neowise_path(\"year8\", \"healpix_k0=1/healpix_k5=1986/part0.snappy.parquet\")\nbiggest_file = neowise_path(\"year1\", \"healpix_k0=2/healpix_k5=2551/part0.snappy.parquet\")","key":"GXVKEwRu11"},{"type":"output","id":"80lssVnOycpgOt7-W3JKf","data":[],"key":"RX8XhbHuCK"}],"key":"TKOm2HGP3B"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"children":[{"type":"text","value":"Convenience function for displaying a table size:","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"D24aMoCYCc"}],"key":"untZC3atl4"}],"key":"n3NQRCbKut"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# We'll use this function throughout the notebook to see how big different tables are.\ndef print_table_size(table, pixel_index=None):\n    \"\"\"Prints the shape (rows x columns) and size (GiB) of the given table.\n\n    Parameters\n    ----------\n    table : pyarrow.Table\n        The table for which to print the size.\n    pixel_index : int or str or None\n        The pixel index corresponding to the partition this table was loaded from.\n    \"\"\"\n    if pixel_index is not None:\n        print(f\"pixel index: {pixel_index}\")\n    print(f\"table shape: {table.num_rows:,} rows x {table.num_columns} columns\")\n    print(f\"table size: {sys.getsizeof(table) / 1024**3:.2f} GiB\")","key":"r2RoYrglXY"},{"type":"output","id":"KL6IfGmupPMkvX-iWdkMk","data":[],"key":"MDzcM8avqc"}],"key":"CAvUColojF"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"children":[{"type":"text","value":"3.2 Load NEOWISE metadata as a pyarrow dataset","position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"key":"J9xV1ldpvX"}],"identifier":"id-3-2-load-neowise-metadata-as-a-pyarrow-dataset","label":"3.2 Load NEOWISE metadata as a pyarrow dataset","html_id":"id-3-2-load-neowise-metadata-as-a-pyarrow-dataset","implicit":true,"key":"ouou8DNoas"}],"key":"uiGQwmUIA0"},{"type":"block","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":231,"column":1},"end":{"line":232,"column":1}},"children":[{"type":"text","value":"The metadata contains column names, schema, and row-group statistics for every file in the dataset.\nLater, we will use this pyarrow dataset object to slice and query the catalog in several different ways.","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"RFS8pMWrCu"}],"key":"pDCIQ4uT27"}],"key":"YWzClQOCoa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# This catalog is so big that even the metadata is big.\n# Expect this cell to take about 30 seconds per year.\nfs = pyarrow.fs.S3FileSystem(region=\"us-west-2\", anonymous=True)\n\n# list of datasets, one per year\nyear_datasets = [\n    pyarrow.dataset.parquet_dataset(neowise_path(yr), filesystem=fs, partitioning=\"hive\")\n    for yr in YEARS\n]\n\n# unified dataset, all years\nneowise_ds = pyarrow.dataset.dataset(year_datasets)","key":"Tg2aYzfXUz"},{"type":"output","id":"eRoQDj5SvMXu9tklnLfMv","data":[],"key":"vi1UDDlkXv"}],"key":"D85qiL1O4e"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":249,"column":1},"end":{"line":254,"column":1}},"children":[{"type":"inlineCode","value":"neowise_ds","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"s3JNdURFou"},{"type":"text","value":" is a ","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"HQ8rcLVsF3"},{"type":"link","url":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.UnionDataset.html","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"children":[{"type":"text","value":"UnionDataset","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"Oug18xZsSm"}],"urlSource":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.UnionDataset.html","key":"b3BKRySx8B"},{"type":"text","value":".\nAll methods demonstrated for pyarrow datasets in the AllWISE demo notebook can be used with\n","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"t5Nljuk2oC"},{"type":"inlineCode","value":"neowise_ds","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"uSj2BGKCYK"},{"type":"text","value":" and will be applied to all years as if they were a single dataset.\nIn addition, a separate ","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"t3DjJnM5na"},{"type":"link","url":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Dataset.html","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"children":[{"type":"text","value":"Dataset","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"Pgq7ECQIVv"}],"urlSource":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Dataset.html","key":"zhiNWxfCah"},{"type":"text","value":"\nfor each year is stored in the list attribute ","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"Vd0OaxaOFM"},{"type":"inlineCode","value":"neowise_ds.children","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"y66sKpsRqT"},{"type":"text","value":" (== ","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"nxohfSRACZ"},{"type":"inlineCode","value":"year_datasets","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"sYJwluh9D9"},{"type":"text","value":", loaded above),\nand the same methods can be applied to them individually.","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"vNw71lduPP"}],"key":"LwFnrf4Taf"}],"key":"RqJAYqZ03F"},{"type":"block","position":{"start":{"line":256,"column":1},"end":{"line":256,"column":1}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":258,"column":1},"end":{"line":258,"column":1}},"children":[{"type":"text","value":"4. Example: Slice by partition","position":{"start":{"line":258,"column":1},"end":{"line":258,"column":1}},"key":"A4Lmi3cCk1"}],"identifier":"id-4-example-slice-by-partition","label":"4. Example: Slice by partition","html_id":"id-4-example-slice-by-partition","implicit":true,"key":"yYHwyZRGd1"}],"key":"AmxduCTci1"},{"type":"block","position":{"start":{"line":260,"column":1},"end":{"line":260,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":262,"column":1},"end":{"line":264,"column":1}},"children":[{"type":"text","value":"This example shows how to load data from each partition separately.\nThe actual “slicing” is done by applying a filter to the pyarrow dataset ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"pVqpPtCxEq"},{"type":"inlineCode","value":"neowise_ds","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"oollCPxfg4"},{"type":"text","value":".\nConstructing filters was discussed in the AllWISE notebook linked above.","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"pdWzhUTFlZ"}],"key":"pK87RdDzOm"}],"key":"rwBF9x0osd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# number of order K pixels covering the full sky\nnpixels = hpgeom.nside_to_npixel(hpgeom.order_to_nside(order=K))\n\n# iterate over all partitions\nfor pix in range(npixels):\n\n    # slice and load to get all rows in this partition, subset of columns\n    pixel_tbl = neowise_ds.to_table(filter=(KFIELD == pix), columns=COLUMN_SUBSET)\n\n    # insert your code here to continue processing\n\n    # we'll just print the table size to get a sense of how much data has been loaded\n    print_table_size(table=pixel_tbl, pixel_index=pix)\n\n    # when done, you may want to delete pixel_tbl to free the memory\n    del pixel_tbl\n    # we'll stop after one partition\n    break","key":"TuMysrg67n"},{"type":"output","id":"ri8WxdaCF9CKJEO-XwdU0","data":[],"key":"LVrOuzSo0a"}],"key":"X3hnuOR1w7"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":287,"column":1},"end":{"line":289,"column":1}},"children":[{"type":"inlineCode","value":"pixel_tbl","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"x4CQ9LzKoQ"},{"type":"text","value":" is a (pyarrow) ","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"WFOUrifW4g"},{"type":"link","url":"https://arrow.apache.org/docs/python/generated/pyarrow.Table.html","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"children":[{"type":"text","value":"Table","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"JQogkW8QUU"}],"urlSource":"https://arrow.apache.org/docs/python/generated/pyarrow.Table.html","key":"x69VmJKCBL"},{"type":"text","value":"\ncontaining all NEOWISE sources with an ra/dec falling within HEALPix order 5 pixel ","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"tau9UXWNR1"},{"type":"inlineCode","value":"pix","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"qLPv3o5jiT"},{"type":"text","value":".\nUse ","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"EC0ZQutAMo"},{"type":"inlineCode","value":"pixel_tbl.to_pandas()","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"eGCFILJWBS"},{"type":"text","value":" to convert the table to a pandas dataframe.","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"rTQzxzqMfi"}],"key":"LalsGfJqTg"}],"key":"HQuMnHAloR"},{"type":"block","position":{"start":{"line":291,"column":1},"end":{"line":291,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"children":[{"type":"text","value":"How big are the partitions? (see Appendix for details)","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"key":"l1Cm9DvU7B"}],"key":"lHYo0wNgCp"}],"key":"xJo0ttIqzj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# median partition\nmedian_part_tbl = neowise_ds.to_table(\n    filter=(KFIELD == median_part), columns=COLUMN_SUBSET\n)\nprint_table_size(table=median_part_tbl, pixel_index=median_part)","key":"PKhcXUdb6D"},{"type":"output","id":"anycuQlt4Tqy4Rpcy_-am","data":[],"key":"EwT2nqH0Nr"}],"key":"MVEWReXi8x"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":303,"column":1},"end":{"line":305,"column":1}},"children":[{"type":"text","value":"Often only a few columns are needed for processing, so most partitions will fit comfortably in memory.\n(The recommended maximum for an in-memory table/dataframe is typically 1GB, but there is\nno strict upper limit -- performance will depend on the compute resources available.)","position":{"start":{"line":303,"column":1},"end":{"line":303,"column":1}},"key":"ZMgaRWm3Lv"}],"key":"GyTSHasHSa"},{"type":"paragraph","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"children":[{"type":"text","value":"However, beware that the largest partitions are quite large:","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"key":"jys7SdcYkN"}],"key":"YPQkH9GtE6"}],"key":"pgi6Gp9ksY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# biggest partition\n# this is very large, so we'll restrict the number of columns to one\nbiggest_part_tbl = neowise_ds.to_table(\n    filter=(KFIELD == biggest_part), columns=COLUMN_SUBSET[:1]\n)\nprint_table_size(table=biggest_part_tbl, pixel_index=biggest_part)\n\n# Additional filters can be included to reduce the number of rows if desired.\n# Another option is to load individual files.","key":"rAEseuDbV6"},{"type":"output","id":"ZdB_rb_DkcIefBaEGEpos","data":[],"key":"qYmydNcAVu"}],"key":"xvVYhfjXH3"},{"type":"block","children":[],"key":"R3LpXoiGG0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# cleanup\ndel median_part_tbl\ndel biggest_part_tbl","key":"ZzZUy6pvyW"},{"type":"output","id":"zn2KtoFtKLAuPe6R75wuo","data":[],"key":"YbUZIEe8CH"}],"key":"uWTWuWoMq4"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"children":[{"type":"text","value":"5. Example: Slice by file","position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"key":"I6rjOfsuwz"}],"identifier":"id-5-example-slice-by-file","label":"5. Example: Slice by file","html_id":"id-5-example-slice-by-file","implicit":true,"key":"ByQnfEXkxh"}],"key":"BcFTqtHnpK"},{"type":"block","position":{"start":{"line":329,"column":1},"end":{"line":329,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":331,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"text","value":"If you don’t need data for all years at the same time, you may want to load individual files.\nGenerally, there is 1 file per partition per year, but a few partitions are as large as 6+ files per year.\nMost of the files are about 0.3GB (compressed on disk) but about 1% are > 1GB.\nThus it should be reasonable to load at least a subset of columns for every row in a file.","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"key":"kwmaKNHyi7"}],"key":"FyiimpJuYP"}],"key":"RQ0VBDBvau"},{"type":"block","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":338,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"text","value":"The actual “slicing” here is done by using ","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"zE4JH45DQv"},{"type":"inlineCode","value":"neowise_ds","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"lL0Mc97LHE"},{"type":"text","value":" to access a\ndataset ","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"yZSLIqlC0j"},{"type":"link","url":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Fragment.html","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"children":[{"type":"text","value":"Fragment","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"mc80w3TPC5"}],"urlSource":"https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Fragment.html","key":"KL4WoXtE9B"},{"type":"text","value":"\n(","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"YSJ9UjoMX5"},{"type":"inlineCode","value":"frag","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"bwyVhu8S1D"},{"type":"text","value":" in the code below) which represents a single file.","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"ysTvkHCCgG"}],"key":"MhWrdTios8"}],"key":"Fcw4BwYeFQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# slice by file and iterate\nfor frag in neowise_ds.get_fragments():\n    # load the slice to get every row in the file, subset of columns\n    file_tbl = frag.to_table(columns=COLUMN_SUBSET)\n\n    # insert your code here to continue processing the file as desired\n\n    # if you need to see which file this is, parse the path\n    print(f\"file path: {frag.path}\")\n    # let's see how much data this loaded\n    print_table_size(table=file_tbl)\n\n    # again, we'll stop after one\n    del file_tbl\n    break","key":"LFQE42Q0lM"},{"type":"output","id":"AQ6U9rB3MhxZhzwO1z789","data":[],"key":"IUcYfVU27x"}],"key":"eekP9lScck"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":360,"column":1},"end":{"line":361,"column":1}},"children":[{"type":"text","value":"This can be combined with the previous example to iterate over the files in a single partition\n(left as an exercise for the reader).","position":{"start":{"line":360,"column":1},"end":{"line":360,"column":1}},"key":"jUkyDB9U06"}],"key":"S3QE4XUwbd"}],"key":"A6BdWiKQw2"},{"type":"block","position":{"start":{"line":363,"column":1},"end":{"line":363,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"children":[{"type":"text","value":"How big are the files?","position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"key":"S2f9z5MM6d"}],"key":"MVzMZWbJY5"}],"key":"V3HwUCiF1K"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# median file\nmedian_file_frag = [\n    frag for frag in neowise_ds.get_fragments() if frag.path == median_file\n][0]\nmedian_file_tbl = median_file_frag.to_table(columns=COLUMN_SUBSET)\nprint_table_size(table=median_file_tbl)","key":"EoCxM7HEld"},{"type":"output","id":"WlWTVm649pkMkFWvpvI_S","data":[],"key":"XrF96l8dUI"}],"key":"WUrie32zV2"},{"type":"block","children":[],"key":"L3Jr4MWdNi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# biggest file\nbiggest_file_frag = [\n    frag for frag in neowise_ds.get_fragments() if frag.path == biggest_file\n][0]\nbiggest_file_tbl = biggest_file_frag.to_table(columns=COLUMN_SUBSET)\nprint_table_size(table=biggest_file_tbl)","key":"QlMqJac1Qe"},{"type":"output","id":"zgFCIoXyiDXgDiHpZjrl7","data":[],"key":"Uf5mP6C0Dv"}],"key":"jcLlHNpZJ0"},{"type":"block","children":[],"key":"VLrmLtonh6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# cleanup\ndel median_file_tbl\ndel biggest_file_tbl","key":"zeWT401o7a"},{"type":"output","id":"8uF0aOyUR-i0fFKcH7KGM","data":[],"key":"TuGGi1A8yk"}],"key":"qR2GrrKp3o"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":391,"column":1},"end":{"line":391,"column":1}},"children":[{"type":"text","value":"6. Example: Slice by year","position":{"start":{"line":391,"column":1},"end":{"line":391,"column":1}},"key":"ojp4RFtwvt"}],"identifier":"id-6-example-slice-by-year","label":"6. Example: Slice by year","html_id":"id-6-example-slice-by-year","implicit":true,"key":"in3Y2NcfOs"}],"key":"UUC5nEkvlz"},{"type":"block","position":{"start":{"line":393,"column":1},"end":{"line":393,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":395,"column":1},"end":{"line":399,"column":1}},"children":[{"type":"text","value":"If you want to handle the years independently you can work with the per-year datasets.\nWe actually created these “slices” in the Setup section with ","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"WlQwovH8rc"},{"type":"inlineCode","value":"year_datasets","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"P8EQwthNZc"},{"type":"text","value":", and that\nsame list is now accessible in ","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"tbRYz7UXQM"},{"type":"inlineCode","value":"neowise_ds.children","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"hoTqsGxldJ"},{"type":"text","value":" used below.\nAny of the techniques shown in this notebook or those listed under “See also” can also\nbe applied to the per-year datasets.","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"FheUUhUBCR"}],"key":"b4AhFhIZt7"}],"key":"nguiPJILM9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# slice by year and iterate. zip with YEARS so that we know which slice this is.\nfor year, year_ds in zip(YEARS, neowise_ds.children):\n    # insert your code here to process year_ds as desired.\n    # filter and load, iterate over partitions or files, etc.\n\n    # we'll just look at some basic metadata.\n    num_rows = sum(frag.metadata.num_rows for frag in year_ds.get_fragments())\n    num_files = len(year_ds.files)\n    print(f\"NEOWISE {year} dataset: {num_rows:,} rows in {num_files:,} files\")","key":"HALxnjkyfG"},{"type":"output","id":"O6_1nG3pfwmYsQAE8TEWn","data":[],"key":"rt13rRyAYK"}],"key":"tIUxo6IQp7"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":413,"column":1},"end":{"line":413,"column":1}},"children":[{"type":"text","value":"Appendix","position":{"start":{"line":413,"column":1},"end":{"line":413,"column":1}},"key":"eyF0LJQg3O"}],"identifier":"appendix","label":"Appendix","html_id":"appendix","implicit":true,"key":"ZlnlYch6ol"}],"key":"x1GG7FfOUj"},{"type":"block","position":{"start":{"line":415,"column":1},"end":{"line":415,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":417,"column":1},"end":{"line":417,"column":1}},"children":[{"type":"text","value":"A.1 Considerations when extending to specific use cases","position":{"start":{"line":417,"column":1},"end":{"line":417,"column":1}},"key":"nucJOP1kM5"}],"identifier":"a-1-considerations-when-extending-to-specific-use-cases","label":"A.1 Considerations when extending to specific use cases","html_id":"a-1-considerations-when-extending-to-specific-use-cases","implicit":true,"key":"gf6CTdlsQs"},{"type":"paragraph","position":{"start":{"line":419,"column":1},"end":{"line":421,"column":1}},"children":[{"type":"text","value":"Because the catalog is so large, you will need to carefully consider your specific problem and\ndetermine how to slice and filter the data most efficiently.\nThere is no one right answer; it will depend on the use case.","position":{"start":{"line":419,"column":1},"end":{"line":419,"column":1}},"key":"ggcBEEXoFI"}],"key":"b9IStv1Ql6"},{"type":"heading","depth":4,"position":{"start":{"line":423,"column":1},"end":{"line":423,"column":1}},"children":[{"type":"text","value":"A.1.1 Filtering","position":{"start":{"line":423,"column":1},"end":{"line":423,"column":1}},"key":"fdZS8gCILm"}],"identifier":"a-1-1-filtering","label":"A.1.1 Filtering","html_id":"a-1-1-filtering","implicit":true,"key":"jmmamNECKX"},{"type":"paragraph","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"children":[{"type":"text","value":"Filter out as much data as possible as early as possible. Ideas to consider are:","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"s9unScr765"}],"key":"buMirwYrlW"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":427,"column":1},"end":{"line":448,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":427,"column":1},"end":{"line":432,"column":1}},"children":[{"type":"text","value":"With the Parquet file format, you can apply filters during the read to avoid loading\nrows that you don’t need.","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"key":"Q91WYFBzCe"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":429,"column":1},"end":{"line":432,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"children":[{"type":"text","value":"Pandas (not demonstrated here) supports basic filters.","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"key":"K1ncFPs1mx"}],"key":"Byrn1FvoRg"},{"type":"listItem","spread":true,"position":{"start":{"line":430,"column":1},"end":{"line":432,"column":1}},"children":[{"type":"text","value":"PyArrow (demonstrated here) also supports complex filters which allow you to compare\nvalues between columns and/or construct new columns on the fly (e.g., subtracting\nmagnitude columns to construct a new color column, as done in the AllWISE notebook).","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"key":"VMpYPyAe6Y"}],"key":"ownVtiSU5p"}],"key":"XF6Gvwt6rU"}],"key":"MJWt1J6As1"},{"type":"listItem","spread":true,"position":{"start":{"line":433,"column":1},"end":{"line":439,"column":1}},"children":[{"type":"text","value":"Queries (i.e., loading data by applying filters) will be ","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"Wbn52xL9Kj"},{"type":"emphasis","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"children":[{"type":"text","value":"much","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"Qet97Nfrmr"}],"key":"pQ0e6Hqz4G"},{"type":"text","value":" more efficient when they\ninclude a filter on the partitioning column (‘healpix_k5’; demonstrated above).","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"e2lb5dX3Sb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":435,"column":1},"end":{"line":439,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":435,"column":1},"end":{"line":436,"column":1}},"children":[{"type":"text","value":"Notice both that this is essentially equivalent to slicing by partition and that\nyou can filter for more than one partition at a time.","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"key":"x3BEclAplp"}],"key":"wncT84mkZc"},{"type":"listItem","spread":true,"position":{"start":{"line":437,"column":1},"end":{"line":439,"column":1}},"children":[{"type":"text","value":"This is highly recommended even if your use case doesn’t explicitly care about it.\nExceptions include situations where you’re working with individual files and when\nit’s impractical or counterproductive for the science.","position":{"start":{"line":437,"column":1},"end":{"line":437,"column":1}},"key":"qOt6RRPbsh"}],"key":"gZ4Syp2U3E"}],"key":"eIM6FH0yFN"}],"key":"xMLoVJcooF"},{"type":"listItem","spread":true,"position":{"start":{"line":440,"column":1},"end":{"line":440,"column":1}},"children":[{"type":"text","value":"You should also include filters specific to your use case if possible.","position":{"start":{"line":440,"column":1},"end":{"line":440,"column":1}},"key":"ZJ9jB4yIIj"}],"key":"jL5tUC05VU"},{"type":"listItem","spread":true,"position":{"start":{"line":441,"column":1},"end":{"line":448,"column":1}},"children":[{"type":"text","value":"Exceptions: Sometimes it’s not easy to write a dataset filter for the query.\nA cone search is a common example.\nIn principal it could be written as a PyArrow dataset filter, but in practice the correct\nformula is much too complicated.\nIn this case, it’s easier to write dataset filters for broad RA and Dec limits and then\ndo the actual cone search using ","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"Z6M70OP6vd"},{"type":"inlineCode","value":"astropy","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"xAeS16P4cD"},{"type":"text","value":".\nThis approach is still quite performant (see the NEOWISE light curves notebook).","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"p178ad86IK"}],"key":"UmXOJoGjob"}],"key":"sqrLbcqub7"},{"type":"heading","depth":4,"position":{"start":{"line":449,"column":1},"end":{"line":449,"column":1}},"children":[{"type":"text","value":"A.1.2 Slicing","position":{"start":{"line":449,"column":1},"end":{"line":449,"column":1}},"key":"XPSGBPqjHP"}],"identifier":"a-1-2-slicing","label":"A.1.2 Slicing","html_id":"a-1-2-slicing","implicit":true,"key":"SClAx7AEmi"},{"type":"paragraph","position":{"start":{"line":451,"column":1},"end":{"line":451,"column":1}},"children":[{"type":"text","value":"Slice the dataset in some way(s), then iterate and/or parallelize over the slices. Ideas to consider are:","position":{"start":{"line":451,"column":1},"end":{"line":451,"column":1}},"key":"ZzDrNITPxO"}],"key":"SpBcs3NboD"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":453,"column":1},"end":{"line":463,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":453,"column":1},"end":{"line":458,"column":1}},"children":[{"type":"text","value":"Choose your slices so that you can:","position":{"start":{"line":453,"column":1},"end":{"line":453,"column":1}},"key":"x40Qtczgdw"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":454,"column":1},"end":{"line":458,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":454,"column":1},"end":{"line":456,"column":1}},"children":[{"type":"text","value":"Run your processing code on one slice independently. For example, if your code must\nsee all the data for some target object (RA and Dec) at the same time, you may\nslice the dataset by partition, but don’t slice it by year.","position":{"start":{"line":454,"column":1},"end":{"line":454,"column":1}},"key":"c0xhxerMWL"}],"key":"PjKW9KXL8v"},{"type":"listItem","spread":true,"position":{"start":{"line":457,"column":1},"end":{"line":458,"column":1}},"children":[{"type":"text","value":"Load all data in the slice into memory at once (after applying your filters during the read).\nThis notebook shows how to determine how big a slice of data is in order to guide this decision.","position":{"start":{"line":457,"column":1},"end":{"line":457,"column":1}},"key":"skNDDTdaVB"}],"key":"Tp56yD7pcY"}],"key":"JUlrxC1tO3"}],"key":"EXI2LZavTe"},{"type":"listItem","spread":true,"position":{"start":{"line":459,"column":1},"end":{"line":460,"column":1}},"children":[{"type":"text","value":"By default, slice by partition. If this is too much data, you may also want to slice\nby year and/or file.","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"key":"NpJUIxatHb"}],"key":"lEv7pzOCKe"},{"type":"listItem","spread":true,"position":{"start":{"line":461,"column":1},"end":{"line":463,"column":1}},"children":[{"type":"text","value":"If you have enough memory to load more than one slice simultaneously, parallelize over\nthe slices to speed up your code.","position":{"start":{"line":461,"column":1},"end":{"line":461,"column":1}},"key":"J7P0Dmzes8"}],"key":"qqXOyOzP5S"}],"key":"XyAMIyMcm2"},{"type":"heading","depth":3,"position":{"start":{"line":464,"column":1},"end":{"line":464,"column":1}},"children":[{"type":"text","value":"A.2 Inspect dataset stats","position":{"start":{"line":464,"column":1},"end":{"line":464,"column":1}},"key":"i2TbObioSj"}],"identifier":"a-2-inspect-dataset-stats","label":"A.2 Inspect dataset stats","html_id":"a-2-inspect-dataset-stats","implicit":true,"key":"sywCQjI4sC"}],"key":"YN7IWwCKSo"},{"type":"block","position":{"start":{"line":466,"column":1},"end":{"line":466,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":468,"column":1},"end":{"line":469,"column":1}},"children":[{"type":"text","value":"When deciding how to slice and filter the dataset, it can be useful to understand\ndataset statistics like partition and file sizes.","position":{"start":{"line":468,"column":1},"end":{"line":468,"column":1}},"key":"X1IP5DE6b5"}],"key":"yLR7V31YzQ"}],"key":"LBSluckE7G"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def pixel_index_from_path(path, k_column=KCOLUMN):\n    \"\"\"Parse the path and return the partition pixel index.\n\n    Parameters\n    ----------\n    path : str\n        The path to parse.\n    k_column : str (optional)\n        Name of the partitioning column.\n\n    Returns\n    -------\n    int\n        The partition pixel index parsed from the path.\n    \"\"\"\n    pattern = rf\"({k_column}=)([0-9]+)\"  # matches strings like \"healpix_k5=1124\"\n    return int(re.search(pattern, path).group(2))  # pixel index, e.g., 1124","key":"k6zjFfXQ0V"},{"type":"output","id":"hjsaM44nniHkfwmr14CwM","data":[],"key":"IKh6d4kuPA"}],"key":"V6EZaG9kcj"},{"type":"block","children":[],"key":"SIsEAEa39Z"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# load some file statistics to a dataframe\nfile_stats = pd.DataFrame(\n    columns=[\"path\", KCOLUMN, \"numrows\"],\n    data=[\n        (frag.path, pixel_index_from_path(frag.path), frag.metadata.num_rows)\n        for frag in neowise_ds.get_fragments()\n    ],\n)","key":"FPBT8fpw8A"},{"type":"output","id":"_3ReAAWuJ232dTOxC_avX","data":[],"key":"EMleIwJa7d"}],"key":"RpA8SXlI3K"},{"type":"block","children":[],"key":"aWzQzJh7Km"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"file_stats.sample(5)","key":"AhwvBwGBiK"},{"type":"output","id":"SKODBFrIwg3QTkEsHk0zV","data":[],"key":"gZ17PkR1z7"}],"key":"rl05DdktvL"},{"type":"block","children":[],"key":"MvtOLCuxXW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"file_stats.describe()","key":"ImdEMQaVTn"},{"type":"output","id":"oRCqJkA_LUy4sMzgldGtn","data":[],"key":"qe0oz0JHuE"}],"key":"GrdSVvdLZS"},{"type":"block","children":[{"type":"heading","depth":4,"position":{"start":{"line":510,"column":1},"end":{"line":510,"column":1}},"children":[{"type":"text","value":"A.2.1 Dataset statistics per file","position":{"start":{"line":510,"column":1},"end":{"line":510,"column":1}},"key":"T2jMw44s1M"}],"identifier":"a-2-1-dataset-statistics-per-file","label":"A.2.1 Dataset statistics per file","html_id":"a-2-1-dataset-statistics-per-file","implicit":true,"key":"P1yvvQvw8L"}],"key":"hSDqpOkPgs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# visualize distribution of file sizes (number of rows)\nax = file_stats.numrows.hist(log=True)\nax.set_xlabel(\"Number of rows\")\nax.set_ylabel(\"Number of files\")","key":"N2iA0TBPEd"},{"type":"output","id":"9NBbudG0Pyj8IYmv99tru","data":[],"key":"vVBPvGIVsU"}],"key":"CGFG92iAfw"},{"type":"block","children":[],"key":"Fj9rtRTZ3R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# largest file\nfile_stats.loc[file_stats.numrows == file_stats.numrows.max()].head(1)","key":"yf7V9V4Vt4"},{"type":"output","id":"so0YFTAiZ_s-pAKC8FvYT","data":[],"key":"fwnOlqWDLT"}],"key":"AzGdz5Sp1K"},{"type":"block","children":[],"key":"LG3j2iNei7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# median file\nfile_stats.sort_values(\"numrows\").iloc[len(file_stats.index) // 2]","key":"dlY6E8WNvx"},{"type":"output","id":"uIzRkUSR5hWwqFHasFdD7","data":[],"key":"hRga7GeuUP"}],"key":"PYAF92DpOX"},{"type":"block","children":[{"type":"heading","depth":4,"position":{"start":{"line":529,"column":1},"end":{"line":529,"column":1}},"children":[{"type":"text","value":"A.2.2 Dataset statistics per partition","position":{"start":{"line":529,"column":1},"end":{"line":529,"column":1}},"key":"rQtp5JLmxK"}],"identifier":"a-2-2-dataset-statistics-per-partition","label":"A.2.2 Dataset statistics per partition","html_id":"a-2-2-dataset-statistics-per-partition","implicit":true,"key":"nf9eG7Kn8T"}],"key":"KWPJAZ69Io"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# get stats per partition\nk_groups = file_stats[[KCOLUMN, \"numrows\"]].groupby(KCOLUMN)\nper_part = k_groups.sum()\nper_part[\"numfiles\"] = k_groups.count()","key":"cQNwiZDEaf"},{"type":"output","id":"M8UPbiizw-2b7m7PEMw31","data":[],"key":"sLD9MFxaWf"}],"key":"YQSArZv5DC"},{"type":"block","children":[],"key":"oe1PbbMb1G"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"per_part.sample(5)","key":"S3feb4eNt9"},{"type":"output","id":"xGFZrldsQsrJHSH2w0z0Y","data":[],"key":"mPHOJKSEBR"}],"key":"SgBMx6kZ6P"},{"type":"block","children":[],"key":"Ex6tDEhcGU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"per_part.describe()","key":"xdZyKIke0K"},{"type":"output","id":"Ye43mGFyzFPK1wF-4kVPs","data":[],"key":"fOhVqMO9u7"}],"key":"TMulD7q06A"},{"type":"block","children":[],"key":"pS0iLctCDp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# visualize number of rows per partition\nper_part.numrows.plot(\n    logy=True, xlabel=f\"{KCOLUMN} pixel index\", ylabel=\"Number of rows per partition\"\n)","key":"slZobpFzuY"},{"type":"output","id":"AT91tsaDXp50FL3W4UAvO","data":[],"key":"wCEMhcafvt"}],"key":"UYa3Ucx9F3"},{"type":"block","children":[],"key":"dYDUZG1wp0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# largest partition\nper_part.loc[per_part.numrows == per_part.numrows.max()]","key":"IU63DSJxp1"},{"type":"output","id":"AMoHDIFsmjPR5VGBafXV0","data":[],"key":"mBftxOe56X"}],"key":"jIhEAEw7eY"},{"type":"block","children":[],"key":"J9szKMbF6I"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# median partition\nper_part.sort_values(\"numrows\").iloc[len(per_part.index) // 2]","key":"ldqBq2icmK"},{"type":"output","id":"Oq2Iv88h3YIfbebJcfH7A","data":[],"key":"Gky5YveG6F"}],"key":"p3jKnFgUFP"},{"type":"block","children":[{"type":"thematicBreak","position":{"start":{"line":563,"column":1},"end":{"line":563,"column":1}},"key":"cI2LSnbtzH"},{"type":"heading","depth":2,"position":{"start":{"line":565,"column":1},"end":{"line":565,"column":1}},"children":[{"type":"text","value":"About this notebook","position":{"start":{"line":565,"column":1},"end":{"line":565,"column":1}},"key":"eViQa0zKSz"}],"identifier":"about-this-notebook","label":"About this notebook","html_id":"about-this-notebook","implicit":true,"key":"erGUFuTSDS"},{"type":"paragraph","position":{"start":{"line":567,"column":1},"end":{"line":567,"column":1}},"children":[{"type":"strong","position":{"start":{"line":567,"column":1},"end":{"line":567,"column":1}},"children":[{"type":"text","value":"Author:","position":{"start":{"line":567,"column":1},"end":{"line":567,"column":1}},"key":"Iz5RTWeYsk"}],"key":"fjfGhrtT7u"},{"type":"text","value":" Troy Raen (IRSA Developer) and the IPAC Science Platform team","position":{"start":{"line":567,"column":1},"end":{"line":567,"column":1}},"key":"Oh7wr6Isx9"}],"key":"xVYzlhI7dJ"},{"type":"paragraph","position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"children":[{"type":"strong","position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"children":[{"type":"text","value":"Updated:","position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"key":"I9sS5qfvs7"}],"key":"wDKKWOavNC"},{"type":"text","value":" 2025-03-07","position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"key":"Tv1DRmvhFF"}],"key":"tcepnxQR6m"},{"type":"paragraph","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"children":[{"type":"strong","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"children":[{"type":"text","value":"Contact:","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"key":"grFI9MdNxB"}],"key":"aTu88sQ2oV"},{"type":"text","value":" ","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"key":"LIS4iGIJki"},{"type":"link","url":"https://irsa.ipac.caltech.edu/docs/help_desk.html","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"children":[{"type":"text","value":"the IRSA Helpdesk","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"key":"YEs7Y9BqmY"}],"urlSource":"https://irsa.ipac.caltech.edu/docs/help_desk.html","key":"gn0wuN38wM"},{"type":"text","value":" with questions or reporting problems.","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"key":"Kla0uuvQn1"}],"key":"NdHTrMfEva"}],"key":"YUFNjpUva3"}],"key":"rGhplVjuXs"},"references":{"cite":{"order":["Gorski_2005"],"data":{"Gorski_2005":{"label":"Gorski_2005","enumerator":"1","doi":"10.1086/427976","html":"Gorski, K. M., Hivon, E., Banday, A. J., Wandelt, B. D., Hansen, F. K., Reinecke, M., & Bartelmann, M. (2005). HEALPix: A Framework for High‐Resolution Discretization and Fast Analysis of Data Distributed on the Sphere. <i>The Astrophysical Journal</i>, <i>622</i>(2), 759–771. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1086/427976\">10.1086/427976</a>","url":"https://doi.org/10.1086/427976"}}}},"footer":{"navigation":{"prev":{"title":"Using Firefly visualization tools to understand the light curves of Solar System objects","url":"/neowise-light-curve-demo","group":"NEOWISE"},"next":{"title":"Make Light Curves from NEOWISE Single-exposure Source Table","url":"/neowise-source-table-lightcurves","group":"NEOWISE"}}},"domain":"http://localhost:3000"}